{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mnist DCGan.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOaZkRWjrTfTtNLcWMa8cQ7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsC-zwOcQoQ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8q8uQjWyQ8Q5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Activation, BatchNormalization, Dense, Dropout, Flatten, Reshape\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXuaHsOIxl5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_rows = 28\n",
        "img_cols = 28\n",
        "channels = 1\n",
        "\n",
        "# Input shape\n",
        "img_shape = (img_rows, img_cols, channels)\n",
        "\n",
        "# Noise Vector\n",
        "z_dim = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYejDe1H4bDd",
        "colab_type": "text"
      },
      "source": [
        "#### Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbaYfr9vySQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_generator(z_dim):\n",
        "  model = Sequential()\n",
        "  \n",
        "  # reshape to 7x7x256 using a dense layer\n",
        "  model.add(Dense(256 * 7 * 7, input_dim=z_dim))\n",
        "  model.add(Reshape((7, 7, 256)))\n",
        "  \n",
        "  # transposed conv operation 7x7x256 to 14x14x128\n",
        "  model.add(Conv2DTranspose(128, kernel_size=3, strides=2, padding='same'))\n",
        "  \n",
        "  # Batch normalization\n",
        "  model.add(BatchNormalization())\n",
        "  \n",
        "  # LeakyRelu activation\n",
        "  model.add(LeakyReLU(alpha=0.01))\n",
        "  \n",
        "  # transposed conv, 14x14x128 ==> 14x14x64\n",
        "  model.add(Conv2DTranspose(64, kernel_size=3, strides=1, padding='same'))\n",
        "  \n",
        "  # Batch normalization\n",
        "  model.add(BatchNormalization())\n",
        "  \n",
        "  # LeakyRelu activation\n",
        "  model.add(LeakyReLU(alpha=0.01))\n",
        "  \n",
        "  # transposed conv, 14x14x128 ==> 14x14x64\n",
        "  model.add(Conv2DTranspose(1, kernel_size=3, strides=2, padding='same'))\n",
        "  \n",
        "  # tanh activation\n",
        "  model.add(Activation('tanh'))\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOLFEgQP6o6f",
        "colab_type": "text"
      },
      "source": [
        "#### Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aP8SLzK6m1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_discriminator(img_shape):\n",
        "  model = Sequential()\n",
        "  \n",
        "  # Conv layer 28x28x1 ==> 14x14x32\n",
        "  model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding='same'))  \n",
        "  \n",
        "  # LeakyRelu activation\n",
        "  model.add(LeakyReLU())\n",
        "  \n",
        "  # Conv layer 14x14x32 ==> 7x7x64, batchnorm and Lrelu activation\n",
        "  model.add(Conv2D(64, kernel_size=3, strides=2, input_shape=img_shape, padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(LeakyReLU(alpha=0.01))\n",
        "  \n",
        "  # Conv layer 7x7x64 ==> 3x3x128\n",
        "  model.add(Conv2D(128, kernel_size=3, strides=2, input_shape=img_shape, padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(LeakyReLU(alpha=0.01))\n",
        "  \n",
        "  # Output layer with sigmoid activation\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBPHcwx--QPV",
        "colab_type": "text"
      },
      "source": [
        "#### Combine gen and dis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dfGH6lW90BO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_gan(gen, dis):\n",
        "  model = Sequential()\n",
        "  \n",
        "  model.add(gen)\n",
        "  model.add(dis)\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8Umqlll-jYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build and compile the discriminator\n",
        "discriminator = build_discriminator(img_shape)\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "\n",
        "# Build Generator\n",
        "generator = build_generator(z_dim)\n",
        "\n",
        "# Keep Discriminator parameters constant for Generator training\n",
        "discriminator.trainable = False\n",
        "\n",
        "# Build and compile GAN model with fixed Discriminator to train the Generator\n",
        "gan = build_gan(generator, discriminator)\n",
        "gan.compile(loss='binary_crossentropy', optimizer=Adam())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzDOzEzKmHvm",
        "colab_type": "text"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CO7X5zbL-63V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "losses = []\n",
        "accuracies = []\n",
        "iteration_checkpoints = []\n",
        "\n",
        "\n",
        "def train(iterations, batch_size, sample_interval):\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}